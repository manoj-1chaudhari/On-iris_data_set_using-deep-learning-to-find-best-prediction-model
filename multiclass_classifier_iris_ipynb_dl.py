# -*- coding: utf-8 -*-
"""multiclass_classifier iris.ipynb DL

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fSrKavxaomqYUcdrG-bgjyt5OVkmDfXf
"""



"""#using deep learnig on iris data set to find best accurasy"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

#to load dataset
df=pd.read_csv("/content/drive/MyDrive/DEEP LEARNING/iris.csv")

#To show first 5 records
df.head()

#To check null values
df.isnull().sum()

#To check datatypes
df.dtypes

#To check duplicates row
df.duplicated().sum()

#To delete duplicates row permanently
df.drop_duplicates(inplace=True)

#To check duplicates row
df.duplicated().sum()

#How many labels/classes 
df['species'].value_counts()

plt.figure(figsize=(8,18)) #width,height
sns.countplot(data=df,x="species")
f=df['species'].value_counts()
plt.yticks(f)
plt.show()

#convert object type column species into number with the help of LabelEncoder
from sklearn.preprocessing import LabelEncoder
#create object of LabelEncoder class
le=LabelEncoder()
df['species']=le.fit_transform(df['species'])
df.dtypes

#select input and output from dataset
x=df.drop('species',axis=1)
y=df['species']

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=1,stratify=y)

y_train.value_counts()

from sklearn.preprocessing import StandardScaler
ss=StandardScaler()
x_train=ss.fit_transform(x_train)
x_test=ss.transform(x_test)

import tensorflow as tf

#create modelmof sequential class
model=tf.keras.models.Sequential([
       tf.keras.layers.Dense(units=4,activation="relu",input_shape=(x.shape[1],)),#hidden layer 1
       tf.keras.layers.Dense(units=4,activation="relu"),#hidden layer 2
       tf.keras.layers.Dense(units=3,activation="softmax")])#output

model.summary()#param=no.of new rowa*no of input+bias

#compile the model
model.compile(optimizer="sgd",loss="sparse_categorical_crossentropy",metrics=["accuracy"])

#Early Stopping :
from tensorflow.keras.callbacks import EarlyStopping            
#callbacks inbuilt parameter of fit() 
#create callback : -
#EarlyStopping() inbuilt function
callback=EarlyStopping(
    monitor="val_loss",  #val_loss means testing error
    min_delta=0.00001, #value of lambda 
    patience=20,
    verbose=1,
    mode="auto", #min loss 
    baseline=None,
    restore_best_weights=False
)

#train the model use inbuilt method fit()
trained_model=model.fit(x_train,y_train,epochs=3500,validation_data=(x_test,y_test),callbacks=callback)

#traning
model.evaluate(x_train,y_train)

model.evaluate(x_test,y_test)

#find the prediction means test the model
y_pred=model.predict(x_test).round(2)
y_pred

#list comprehension
y_pred=[np.argmax(i) for i in y_pred]
y_pred

from sklearn.metrics import classification_report,confusion_matrix

print(classification_report(y_test,y_pred))
print(confusion_matrix(y_test,y_pred))

